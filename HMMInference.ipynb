{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63d4b90eb7a248bfb7a15a79602a10d4",
     "grade": false,
     "grade_id": "cell-3eddefb2fba66efc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**<font color='red'> Warning:</font> Make sure this file is named HMMInference.ipynb on Coursera or the submit button will not work.**\n",
    "\n",
    "*If you plan to run the assignment locally:*\n",
    "You can download the assignments and run them locally, but please be aware that as much as we would like our code to be universal, computer platform differences may lead to incorrectly reported errors even on correct solutions. Therefore, we encourage you to validate your solution in Coursera whenever this may be happening. If you decide to run the assignment locally, please: \n",
    "   1. Try to download the necessary data files from your home directory one at a time,\n",
    "   2. Don't update anything other than this Jupyter notebook back to Coursera's servers, and \n",
    "   3. Make sure this notebook maintains its original name after you upload it back to Coursera.\n",
    "   \n",
    "Note: You need to submit the assignment to be graded, and passing the validation button's test does not grade the assignment. The validation button's functionality is exactly the same as running all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d0ed862871c88655fd95e86b2c96f89",
     "grade": false,
     "grade_id": "cell-c5e929b25d638734",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn.hmm import MultinomialHMM\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from aml_utils import test_case_checker, perform_computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "882d237503d3f7fc8acd556d5e7a5638",
     "grade": false,
     "grade_id": "cell-5894d4a3c9abfb8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# *Assignment Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78de0047ae855c35cd105aed3f606467",
     "grade": false,
     "grade_id": "cell-f975b6a1fd9b6d98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is an exercise that implements HMMs (Section 13.2 from the textbook). For this excercise you will use the `hmmlearn` library.\n",
    "\n",
    "In this excercise we will use HMMs to denoise a sequence of hidden states for an autonomous driving system. The data consists on readings of an observed variable corresponding to a label of three types of pavement markings (shoulder marking, center pavement marking, left pavement marking) which we will denote with 0,1,2. There are two hidden states which describe whether a car is centered or not (0,1). The autonomous driving is equipped with a computer vision (CV) system that estimates the hidden state, however, due to several limitations associated to weather, cleanliness of the sensor, and other environmental factors, the readings are noisy and biases the readings to match previously read data. Thus, you are in charge of creating a denoising system such that the estimation of the hidden state may be more realistic. In summary, the data has two columns: `markings` which is the visible label of pavement markings directy gathered with the sensors and that you will use to train the models, and `centered` which is a reference hidden state that is not directly captured by the sensors but is estimated with a CV system. For the sake of simplicity we will not have a separated training and test set.\n",
    "\n",
    "Build the function to compute the cost function of the best path leaving each node at a given iteration of the dynamic programming process (for a given column of the trellis), and also the path. For the sake of simplicity you are given the dynamic programming procedure. You only need to program the computation of the cost function and the identification of the best cost and the index of the best cost. Thus, for the function currentWeightBestPath, you should report (a) the cost (sum of log probabilities) and (b) the index (argument) that optimizes the cost.\n",
    "\n",
    "Notice that the cost function is given by the negative sum of log probabilities:\n",
    "\n",
    "$C_w(j) = \\min_u\\left[−\\log P(X_{w+1} = u|X_w = j) −\\log P(Y_{w+1}|X_{w+1} = u)−C_{w+1}(u)\\right]$\n",
    "\n",
    "$B_w(j) = \\arg\\min_u\\left[−\\log P(X_{w+1} = u|X_w = j) −\\log P(Y_{w+1}|X_{w+1} = u)−C_{w+1}(u)\\right]$\n",
    "\n",
    "\n",
    "This is equivalent to maximize the sum of log probabilities:\n",
    "\n",
    "$C_w(j) = \\max_u\\left[\\log P(X_{w+1} = u|X_w = j) +\\log P(Y_{w+1}|X_{w+1} = u)+C_{w+1}(u)\\right]$\n",
    "$B_w(j) = \\arg\\max_u\\left[\\log P(X_{w+1} = u|X_w = j) +\\log P(Y_{w+1}|X_{w+1} = u)+C_{w+1}(u)\\right]$\n",
    "\n",
    "More details of this implementation are provided below.\n",
    "\n",
    "\n",
    "<font color='red'> <b>Attention:</b> </font> After finishing this notebook, you will need to do a follow-up quiz as well. The overall grade for this asiggnment is based on this notebook and the follow-up quiz.\n",
    "    \n",
    "<font color='red'><b> Warning: </b></font> Using the \"Validate\" button for this assignment may lead to a timeout, please do not use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12c5c5ef0b24af9d3cab58514a1d4d30",
     "grade": false,
     "grade_id": "cell-00f99099f1e1bd81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 0. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "345b53e3c269d749061bfbd3c13bb3e5",
     "grade": false,
     "grade_id": "cell-0604fca81520b642",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 0.1 Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04a6a61f25e40d7ac534db025ef71449",
     "grade": false,
     "grade_id": "cell-4af88cf542531eed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll use a synthetic dataset for this excercise. It consists of a single table with two columns. The `markings` is the visible column corresponds to the observed state of the sequence. The `centered` column is the hidden sequence of states which are a noisy estimate of the hidden state that will be used for comparison purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1c2dae48cafef32a5fc42f4d4df722e",
     "grade": false,
     "grade_id": "cell-9861ea999ef9cee6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 0.2 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d3c125bf5d9d17e9c5c2d3a6c5eb1de",
     "grade": false,
     "grade_id": "cell-affdcdeed9095d01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's extract the data\n",
    "\n",
    "data = pd.read_csv('../HMMInference-lib/data.csv')\n",
    "V = data['Markings'].values\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5db50940bbf8f215259207c672c25c9b",
     "grade": false,
     "grade_id": "cell-331f9abe2a438e80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 0.3 Creating a default set of transition and emision probability matrices and training the HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bf063a2a0020eb5b513527f2e212073",
     "grade": false,
     "grade_id": "cell-bc214472e4b1b38b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Transition Probability Matrix\n",
    "transition_p = np.ones((2, 2))\n",
    "transition_p = transition_p / np.sum(transition_p, axis=1)\n",
    " \n",
    "# Emission Probability Matrix\n",
    "emission_p = np.array(((1, 3, 5), (2, 4, 6)))\n",
    "emission_p = emission_p / np.sum(emission_p, axis=1).reshape((-1, 1))\n",
    " \n",
    "initial_distribution = np.array((0.5, 0.5))\n",
    " \n",
    "\n",
    "print(transition_p)\n",
    "print(emission_p)\n",
    "print(initial_distribution)\n",
    "\n",
    "np.random.seed(37)\n",
    "model = MultinomialHMM(n_components=2,  n_iter=10000).fit(np.reshape(V,[len(V),1]))\n",
    "\n",
    "\n",
    "print(model.n_features)\n",
    "print(model.emissionprob_)\n",
    "print(model.transmat_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db297007ddb8f3d7e075c96da387c382",
     "grade": false,
     "grade_id": "cell-1b49df89d744d0ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <span style=\"color:blue\">Task 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0cb26fdacde62890df0a595ea6095f0f",
     "grade": false,
     "grade_id": "cell-78d94a4fdb4e6f48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "\n",
    "Create a python function to compute the cost of the best path leaving each node at a given iteration of the dynamic programming process (for a given column of the trellis), and also the path. For the sake of simplicity you are given the dynamic programming procedure. You only need to program the computation of the cost function and the identification of the best cost and the index of the best cost. Thus, for the function currentWeightBestPath, you should report (a) the cost (sum of log probabilities) and (b) the index (argument) that optimizes the cost.\n",
    "\n",
    "For the sake of simplicity you can maximize the sum of log probabilities using the formula:\n",
    "\n",
    "$C_w(j) = \\max_u\\left[\\log P(X_{w+1} = u|X_w = j) +\\log P(Y_{w+1}|X_{w+1} = u)+C_{w+1}(u)\\right]$\n",
    "$B_w(j) = \\arg\\max_u\\left[\\log P(X_{w+1} = u|X_w = j) +\\log P(Y_{w+1}|X_{w+1} = u)+C_{w+1}(u)\\right]$\n",
    "\n",
    "Suggestion: build first the sum of log probabilities and use the resulting vector to identify the maximal value of the log probability and the index associated to it:\n",
    "\n",
    "$\\log P(X_{w+1}|X_w) + \\log P(Y_{w+1}|X_{w+1}) + C_{w+1}$\n",
    "\n",
    "The dimension of $\\log P(X_{w+1}|X_w)$ and $C_{w+1}$ is equal to the number of states (in this assignment the numver is 2). $\\log P(Y_{w+1}|X_{w+1}=u)$ is a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def currentWeightBestPath(logP_X_given_X, logP_Y_given_X, Cw1):\n",
    "    \"\"\"\n",
    "    Performs computation of log-probabilities to derive Cw(j) and Bw(j).\n",
    "    for a specific iteration j\n",
    "\n",
    "        Parameters:\n",
    "                logP_X_given_X (np array): Dimension = S (number of states) x 1\n",
    "                logP_Y_given_X (np array): dimension 1x1.  \n",
    "                Cw1 (np array): Dimension= number of states x 1. The value of the previous Cw\n",
    "\n",
    "        Returns:\n",
    "                u (int): the index with maximum sum of log probabilities among S options\n",
    "                maxlogprob (double): the maximum sum of log probabilities among S options\n",
    "    \"\"\"       \n",
    "    assert logP_X_given_X.ndim == 1\n",
    "    assert Cw1.ndim == 1\n",
    "\n",
    "    assert logP_X_given_X.shape[0]==Cw1.shape[0] #== S\n",
    "\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return u,maxplogrob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "476b5d0c5bf67ac420121864b05eb090",
     "grade": false,
     "grade_id": "cell-79924004909a119e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#verify correctness of function\n",
    "\n",
    "index,maxlogp = currentWeightBestPath(np.array([-0.12035803, -1.94017208]), np.array([-1.0447554802085524]), np.array([44.85810916, 49.23474131]))\n",
    "\n",
    "print(maxlogp)\n",
    "\n",
    "assert index==1\n",
    "assert maxlogp==46.24981374979144\n",
    "\n",
    "\n",
    "print(model.emissionprob_)\n",
    "print(model.transmat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "502ec528590105b281f0a47691c48c3e",
     "grade": false,
     "grade_id": "cell-1ee44e9cfc42bf26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def viterbi_Modular(V, a, b, initial_distribution):\n",
    "    \"\"\" \n",
    "    This function simply applies your cost function to traverse the trellis for identification of the optimal path\n",
    "    This implementation uses a forward exploration and then backtracks the computed values to find the optimal path.\n",
    "    \"\"\"\n",
    "    T = V.shape[0]\n",
    "    M = a.shape[0] # or [1]\n",
    " \n",
    "    omega = np.zeros((T, M))\n",
    "    omega[0, :] = np.log(initial_distribution * b[:, V[0]])\n",
    " \n",
    "    prev = np.zeros((T - 1, M))\n",
    " \n",
    "    for t in range(1, T):\n",
    "        for j in range(M):\n",
    "            #transition and emision (transition is associated to X|X since the book uses X to represent the hidden states and emision to Y|X)\n",
    "            u,maxprob = currentWeightBestPath( np.log(a[:, j]),  np.log(b[j, V[t]]) , omega[t - 1]) \n",
    " \n",
    "            # The most probable state given previous state for time t:\n",
    "            prev[t - 1, j] = u #np.argmax(probability)\n",
    " \n",
    "            # The probability of the most probable state at time t:\n",
    "            omega[t, j] = maxprob #np.max(probability)\n",
    "\n",
    " \n",
    "    # Path initialization\n",
    "    S = np.zeros(T,dtype=int)\n",
    " \n",
    "    # Find the most probable last hidden state\n",
    "    last_state = np.argmax(omega[T - 1, :])\n",
    " \n",
    "    S[0] = last_state\n",
    " \n",
    "    backtrack_index = 1\n",
    "    for i in range(T - 2, -1, -1):\n",
    "        S[backtrack_index] = prev[i, int(last_state)]\n",
    "        last_state = prev[i, int(last_state)]\n",
    "        backtrack_index += 1\n",
    " \n",
    "    # backtrack\n",
    "    result = np.flip(S, axis=0)\n",
    " \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the Viterbi algorithm with your cost function implementation using X1\n",
    "np.random.seed(1)\n",
    "X1 = np.random.randint(low=0, high=3, size=(15,))\n",
    "\n",
    "model2=MultinomialHMM(n_components=2,  n_iter=10000).fit(np.reshape(X1,[len(X1),1]))\n",
    "\n",
    "predicted_hidden_sates = viterbi_Modular(X1, model2.transmat_, model2.emissionprob_, initial_distribution)\n",
    "\n",
    "assert np.array_equal(predicted_hidden_sates,  np.array([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1]))\n",
    "\n",
    "print(predicted_hidden_sates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3379c6c37961013ff79295c5958f2500",
     "grade": true,
     "grade_id": "cell-0a5d4a9d0c53bb27",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90991dfabdc92cdbba69f8aba7414669",
     "grade": false,
     "grade_id": "cell-773e5b9cca8326c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "predicted_sequence = viterbi_Modular(V, model.transmat_, model.emissionprob_, initial_distribution)\n",
    "\n",
    "print(predicted_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e04bdd8b4c57a9b66187f7a7f5e9035",
     "grade": false,
     "grade_id": "cell-adc418be0c8f410c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <span style=\"color:blue\">Task 2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "461026c9035184b908b5704bfb3adc91",
     "grade": false,
     "grade_id": "cell-ce54fb2e2e8c0a43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "Implement the HMM sequence using the `predict` funtion of `hmmlearn`. For this you need to make sure the sequence (which is stored in the variable `V`) is formatted as a column vector (one column).\n",
    "\n",
    "The function `predict` is a property of the model's object. Your implementation uses as parameters the `model` trained in the previous cell and the array of observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def predictSequenceReference(observed_values, model):\n",
    "    \"\"\"\n",
    "    Performs prediction of most likely sequence using the hmmlearn library.\n",
    "\n",
    "        Parameters:\n",
    "                observed_values (np array): Observed values\n",
    "                model (hmmlearn.hmm.MultinomialHMM object): the trained HMM  \n",
    "\n",
    "        Returns:\n",
    "                predicted_sequence (np array): the predicted sequence of hidden states\n",
    "    \"\"\"       \n",
    "\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return predicted_sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f1a41f159b26f4cec1efdebb0662a51",
     "grade": false,
     "grade_id": "cell-e5b097015d98f7fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reference_preds=predictSequenceReference(V,model) \n",
    "\n",
    "assert np.array_equal( reference_preds[:10], [0, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "print(reference_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43064a1020f734cd4a460c41abe24516",
     "grade": false,
     "grade_id": "cell-2978a5e4682880c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plotTimeSeries(Q, hidden_states, ylabel, labelvals=('1','2'), printLines=True, xlabel=\"Sequence\", filename = \"HMMTseries_img.png\"):\n",
    "    \"\"\"\n",
    "    Plots the sequence with hidden_states color-coded\n",
    "    Based on Pat Reed's example\n",
    "    \"\"\"\n",
    "\n",
    "    sns.set()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    " \n",
    "    xs = np.arange(len(Q))\n",
    "    masks = hidden_states == 0\n",
    "    ax.scatter(xs[masks], Q[masks], c='r', label=labelvals[0])\n",
    "    masks = hidden_states == 1\n",
    "    ax.scatter(xs[masks], Q[masks], c='b', label=labelvals[1])\n",
    "    if printLines:\n",
    "      ax.plot(xs, Q, c='k')\n",
    "     \n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    fig.subplots_adjust(bottom=0.2)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2, frameon=True)\n",
    "\n",
    " \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b3198bd0c31372a6c4970abced2c126",
     "grade": true,
     "grade_id": "cell-ce94176d91a9165c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a62a8014bdbff0201b6d4a005825f955",
     "grade": false,
     "grade_id": "cell-c90858b8d1a4345a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <span style=\"color:blue\">Task 3</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57ebb83197aa249727a2e6c1b9d5d337",
     "grade": false,
     "grade_id": "cell-b92518d844385e89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "Use the ground truth sequence to format the noisy ground truth, i.e., to replace a value of 0 instead of \"centered\" and a value of 1 instead of \"out\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def formatNoisySequence(noisy_sequence):\n",
    "    \"\"\"\n",
    "    uses a numeric formatting of the original noisy sequence.\n",
    "\n",
    "        Parameters:\n",
    "                noisy_sequence (np array): Sequence with elements in {'centered', 'out'}\n",
    "        Returns:\n",
    "                formatted_noisy_sequence (np array): the numeric version of the original sequence\n",
    "    \"\"\"       \n",
    "\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return formatted_noisy_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3a5b66e6ac355facbfaaeed20e2a38b",
     "grade": false,
     "grade_id": "cell-f8a699aedcd3adaf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "gtValues=formatNoisySequence(data['CenteredNoisy'].values) \n",
    "\n",
    "assert np.array_equal( gtValues[np.concatenate(([0,23,46,65,70], range(81,100)),axis=None)], \n",
    "                      [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,1, 1])\n",
    "\n",
    "gtValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2c6e48797a4740ac0b288cf6cb16748",
     "grade": false,
     "grade_id": "cell-ea823acd4f9d4cef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Comparison of Labels in the Sequence.\\n(Notice that the HMM leads to more stable hidden label esimation than the noisy ground truth)\")\n",
    "\n",
    "valueTest=np.reshape(predicted_sequence,[len(V),1])\n",
    "plotTimeSeries(valueTest, predicted_sequence, 'Centered?', (\"Correct Lane\",\"Outter Border\"))\n",
    "\n",
    "valueTest=np.reshape(reference_preds,[len(V),1])\n",
    "plotTimeSeries(valueTest, reference_preds, 'Centered?', (\"Correct Lane\",\"Outter Border\"))\n",
    "\n",
    "valueTest=np.reshape(gtValues,[len(V),1])\n",
    "plotTimeSeries(valueTest, gtValues, 'Centered?', (\"Correct Lane\",\"Outter Border\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "683ecbdcabb5f39ac7837408cf956c76",
     "grade": false,
     "grade_id": "cell-17c419df21981a6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Comparison of Labels per Observed State.\\n(Notice that the HMM leads to more stable hidden label esimation than the noisy ground truth)\")\n",
    "\n",
    "valueTest=np.reshape(V,[len(V),1])\n",
    "plotTimeSeries(valueTest, predicted_sequence, 'Markings', (\"Correct Lane\",\"Outter Border\"),False)\n",
    "\n",
    "plotTimeSeries(valueTest, reference_preds, 'Markings', (\"Correct Lane\",\"Outter Border\"),False)\n",
    "\n",
    "plotTimeSeries(valueTest, gtValues, 'Markings', (\"Correct Lane\",\"Outter Border\"),False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4beaf998163eeeffd3f6976a958b9aaa",
     "grade": true,
     "grade_id": "cell-672859d0cc685228",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c21521a421b6d643ca0601c64b1cca04",
     "grade": false,
     "grade_id": "cell-c3faf8bd7d57a2ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <span style=\"color:blue\">Task 4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61fc01caedf106ebeaf98b9da3227f55",
     "grade": false,
     "grade_id": "cell-6877a285f81c8c26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Compute the MSE and MAE of the predicted label. While it is not always straighforward to see, an objective of using HMM for data denoising is also minimizing the difference from the noisy states with the objective of maintaining a close resemblance to the expected sequence.\n",
    "\n",
    "To evaluate your implementation of HMM with respect to a previously assign \"ground truth\" you will implement the mean squared error and mean absolute error of the predicted sequence vs. the \"real\" but noisy sequence. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def computeErrors(predictions, realvalues):\n",
    "    \"\"\"\n",
    "    Performs computation of MSE and MAE of the predicted sequence vs. the real sequence\n",
    "\n",
    "        Parameters:\n",
    "                predictions (np array): Dimension = N x 1\n",
    "                realvalues (np array): Dimension = Nx1  \n",
    "\n",
    "        Returns:\n",
    "                MSE (double): the Mean Squared Error\n",
    "                MAE (double): the Mean Absolute Error\n",
    "    \"\"\"       \n",
    "    assert predictions.shape[0]==realvalues.shape[0] #== S\n",
    "\n",
    "    # your code here\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return mse,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b9060672ab3f694a8c8c9a9eab02ec4",
     "grade": false,
     "grade_id": "cell-732826443b1542b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "refmse,refmae = computeErrors(reference_preds,gtValues)\n",
    "\n",
    "mse,mae = computeErrors(predicted_sequence,gtValues)\n",
    "\n",
    "print(\"Errors for your solution: mse: %f, mae: %f\" % ( mse,mae) )\n",
    "\n",
    "print(\"Errors for reference solution: mse: %f, mae: %f\" % (refmse,refmae))\n",
    "\n",
    "assert refmse < 2\n",
    "assert refmae < 0.5\n",
    "assert mse < 2\n",
    "assert mae < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6212321a61964bd6de6aa264bff86290",
     "grade": true,
     "grade_id": "cell-f11a54fa5d18e21d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/HMMInference/HMMInference.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
